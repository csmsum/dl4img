{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM0sekxLLDW3hNJPCXDmnFG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/csmsum/dl4img/blob/main/Practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Preparation"
      ],
      "metadata": {
        "id": "PUKL2KZu_4ul"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GDproNVfxD7W"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "lob_begin_red, log_begin_blue, log_begin_green = '\\033[91m', '\\033[94m', '\\033[92m'\n",
        "log_begin_bold, log_begin_underline = '\\033[1m', '\\033[4m'\n",
        "log_end_format = '\\033p0m'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Neuron"
      ],
      "metadata": {
        "id": "BjucGXJh_kSw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Neuron(object):\n",
        "    def __init__(self, num_input, activation_function):\n",
        "        super().__init__()\n",
        "        self.w = np.random.uniform(size = num_input, low = -1., high = 1.)\n",
        "        self.b = np.random.uniform(size = 1, low = -1., high = 1.)\n",
        "        self.activation_function = activation_function\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = np.dot(x, self.w)+self.b\n",
        "        return self.activation_function(z)"
      ],
      "metadata": {
        "id": "we1vmF-v8blt"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "```\n",
        "class Neuron(object)\n",
        "    super().__init__()\n",
        "```\n",
        "위와 같은 경우는, 파이썬 2의 잔재이다. 당시에는 class 내에 아무것도 들어가지 않을 때 object를 호출하고 object의 속성을 그대로 가져오는 super().__init__()을 함께 활성화했어야만 했다. "
      ],
      "metadata": {
        "id": "HPkx-4Pvf074"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 3\n",
        "step_function = lambda y: 0 if y<=0 else 1\n",
        "perceptron = Neuron(input_size, step_function)"
      ],
      "metadata": {
        "id": "XgkQwPih8ryo"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Regularization"
      ],
      "metadata": {
        "id": "O6m-7BzBhw3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 10\n",
        "img_rows, img_cols, img_ch = 28, 28, 1\n",
        "input_shape = (img_rows, img_cols, img_ch)\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train, x_test = x_train/255.0, x_test/255.0\n",
        "\n",
        "x_train = x_train.reshape(60000, 28, 28, 1)\n",
        "x_test = x_test.reshape(10000, 28, 28, 1)"
      ],
      "metadata": {
        "id": "67yslyZqiGzy",
        "outputId": "6e31d518-758b-406a-d86d-85fac05a1ac0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import (Input, Activation, Dense, Flatten, Conv2D,\n",
        "                                     MaxPooling2D, Dropout, BatchNormalization)\n",
        "epochs = 200\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "wQ7WUNDu_UBw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sGFCzySL_1jw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def conv_layer(x, kernels, bias, s):\n",
        "    z = tf.nn.conv2d(x, kernels, strides = [1,s,s,1], padding = 'VALID') #여기서 [1,s,s,1]은 각각 [Number of inputs, Height, Width, Channel]인데, 이중 N,C는 1 by default이고 H,W는 strides 를 결정한다.\n",
        "    return tf.nn.relu(z + bias)\n",
        "\n",
        "\n",
        "class SimpleConvolutionLayer(tf.keras.layers.Layer): #add_weight 등의 methods들을 사용하기 위해서는 tf.keras.layers.Layer를 상속할 필요가 있다.\n",
        "    def __init__(self, num_kernels = 32, kernel_size = (3,3), stride = 1):\n",
        "        super().__init__()\n",
        "        self.num_kernels = num_kernels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        num_input_ch = input_shape[-1] #이미지를 다룰 땐 BHWC 즉 [Batch_sz, Height, Width, Chanenl순으로 가는게 좋다.]\n",
        "        kernels_shape = (*self.kernel_size, num_input_ch, self.num_kernels)\n",
        "        \"\"\"ㄴtuple이나 list앞의 *은 이들을 순서대로 풀어주는 역할을 한다. 예를 들어 (3,3)은 그냥 3, 3이 되어 나온다.\n",
        "        즉 여기서 기본커널사이즈 33이라고 가정하고 mnist가 흑백이라는 것을 감안,\n",
        "        또 커널 개수를 32라고 가정하면 (3,3,1,32)의 형태가 된다.\"\"\"\n",
        "        glorot_init = tf.initializers.GlorotUniform()\n",
        "        self.kernels = self.add_weight(\n",
        "            name = 'kernels', shape = kernels_shape,\n",
        "            initializer = glorot_init, trainable = True)\n",
        "        self.bias = self.add_weight(\n",
        "            name = 'bias', shape = (self.num_kernels,),\n",
        "            initializer = 'random_normal', trainable = True)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return conv_layer(inputs, self.kernels, self.bias, self.stride)\n",
        "    \n",
        "    def get_config(self):\n",
        "        return {'num_kernels': self.num_kernels,\n",
        "                'kernel_size': self.kernel_size,\n",
        "                'stride': self.strides,\n",
        "                'use_bias': self.use_bias}"
      ],
      "metadata": {
        "id": "KQ4S6FjiD6Yu"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import partial\n",
        "\n",
        "def l2_reg(coef = 1e-2):\n",
        "    return lambda x: tf.reduce_sum(x**2) * coef\n",
        "\n",
        "class ConvWithRegularizers(SimpleConvolutionLayer):\n",
        "    def __init__(self, num_kernels = 32, kernel_size = (3,3), stride = 1,\n",
        "        kernel_regularizer = l2_reg(), bias_regularizer = None):\n",
        "        super().__init__(num_kernels, kernel_size, stride)\n",
        "        self.kernel_regularizer = kernel_regularizer\n",
        "        self.bias_regularizer = bias_regularizer\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        super().build(input_shape)\n",
        "        if self.kernel_regularizer is not None:\n",
        "            self.add_loss(partial(self.kernel_regularizer, self.kernels))\n",
        "        \"\"\"partial 함수는 partial derivative를 가져와주는 함수가 아니다.\n",
        "반대로, self.kernel_regularizer (l2_reg라는 이미 미분된 함수)에서 인수인 self.kernels를\n",
        "이미 쓴 상태로 가져오겠다는 소리이다. 다시 말해서 self.kernels(regularizer함수)를 l2_reg(즉 미분)\n",
        "에 넣은 결과값을 weight에 추가하겠다는 의미이다. \"\"\"\n",
        "        if self.bias_regularizer is not None:\n",
        "            self.add_loss(partial(self.bias_regularizer, self.bias))"
      ],
      "metadata": {
        "id": "wTToB1Z2Gk7d"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv = ConvWithRegularizers(num_kernels = 32, kernel_size = (3,3), stride = 1,\n",
        "                            kernel_regularizer = l2_reg(1.), bias_regularizer = l2_reg(1.))\n",
        "conv.build(input_shape = tf.TensorShape((None, 28, 28, 1)))\n",
        "\n",
        "reg_losses = conv.losses #여기서 conv.losses가 reg_losses로 이어질 수 있는 까닭은 아직 loss를 아무것도 설정하지 않은 상태에서 regularization만 써놨기 때문이다.\n",
        "print('Regularization losses over kernel and bias parameters: {}'.format(\n",
        "    [loss.numpy() for loss in reg_losses]))\n",
        "\n",
        "kernel_norm, bias_norm = tf.reduce_sum(conv.kernels ** 2).numpy(), tf.reduce_sum(conv.bias ** 2).numpy()\n",
        "print('L2 norms of kernel and bias parameters: {}'.format([kernel_norm, bias_norm]))\n"
      ],
      "metadata": {
        "id": "7Uin-_8L2CfO",
        "outputId": "8ecee90d-7e2c-4c4b-870f-bf8e5c5b31a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regularization losses over kernel and bias parameters: [1.9206898, 0.120684355]\n",
            "L2 norms of kernel and bias parameters: [1.9206898, 0.120684355]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "C2ROIZsSJOW0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Input(shape=input_shape),\n",
        "    ConvWithRegularizers(kernel_regularizer=l2_reg(1.), bias_regularizer=l2_reg(1.)),\n",
        "    ConvWithRegularizers(kernel_regularizer=l2_reg(1.), bias_regularizer=l2_reg(1.)),\n",
        "    ConvWithRegularizers(kernel_regularizer=l2_reg(1.), bias_regularizer=l2_reg(1.))  \n",
        "])\n",
        "\n",
        "print('Losses attached to the model and its layers:\\n\\r{} ({} losses)'.format(\n",
        "    [loss.numpy() for loss in model.losses], len(model.losses)))"
      ],
      "metadata": {
        "id": "Og9awW-yG8B3",
        "outputId": "3e9af606-8444-479f-9896-c87f14130704",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Losses attached to the model and its layers:\n",
            "\r[1.8991263, 0.10561776, 31.978502, 0.068846345, 32.577663, 0.09254287] (6 losses)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNet5(Model): #모델은 Layer과 그 확장판을 포함하고 있다. 아까 from tensorflow.keras.models import Model, Sequential\n",
        "                        #에서 import 해놨다. \n",
        "    def __init__(self, num_classes,\n",
        "             kernel_regularizer = l2_reg(), bias_regularizer = l2_reg()):\n",
        "        super(LeNet5, self).__init__()\n",
        "        self.conv1 = ConvWithRegularizers(\n",
        "            6, kernel_size(5,5),\n",
        "            kernel_regularizer = kernel_regularizer, bias_regularizer = bias_regularizer)\n",
        "        self.conv2 = ConvWithRegularizers(\n",
        "            16, kernel_size(5,5),\n",
        "            kernel_regularizer = kernel_regularizer, bias_regularizer = bias_regularizer)\n",
        "        self.max_pool = MaxPooling2D(pool_size = (2,2))\n",
        "        self.flatten = Flatten()\n",
        "        self.dense1 = Dense(120, activation = 'relu')\n",
        "        self.dense2 = Dense(84, activation = 'relu')\n",
        "        self.dense3 = Dense(num_classes, activation = 'softmax')\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.max_pool(self.conv1(x))\n",
        "        x = self.max_pool(self.conv2(x))\n",
        "        x = self.flatten(x)\n",
        "        x = self.dense3(self.dense(self.dense1(x)))\n",
        "        return x"
      ],
      "metadata": {
        "id": "_X7C-8gUI3OW"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.optimizers.SGD()\n",
        "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(batch_size)\n",
        "log_string_template = 'Epoch {0:3}/{1}: main loss = {5}{2:5.3f}{6}; ' + \\\n",
        "                      'reg loss = {5}{3:5.3f}{6}; val acc = {5}{4:5.3f}%{6}'\n",
        "\n",
        "def train_classifier_on_mnist(model, log_frequency = 10):\n",
        "    avg_main_loss = tf.keras.metrics.Mean(name = 'avg_main_loss', dtype = tf.float32)\n",
        "    avg_reg_loss = tf.keras.metrics.Mean(name = 'avg_reg_loss', dtype = tf.float32)    \n",
        "\n",
        "    print(\"Training: {}start{}\".format(log_begin_red, log_end_format))\n",
        "    for epoch in range(epochs):\n",
        "        for (batch_image, batch_gts) in dataset:"
      ],
      "metadata": {
        "id": "nIuQAWOjI3HE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uRTtzCZ3I3AC",
        "outputId": "e11ca22a-5e6a-4b2e-b465-485dcaf32dec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-64c4889a3494>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdataset\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'TensorSliceDataset' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2DyXEE73I2s4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}